{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in /opt/anaconda3/lib/python3.12/site-packages (5.4.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (2.0.1)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.12 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.3.12)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.1.143)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.12->langchain-community) (0.3.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.12->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_7Myivb_KdeTtvUZmMKfB2fpVaixRPYyhzjfVJnxprdGtxB7pSpKnnXXCja3bNYHUqRnegj\"\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"/Users/nandinigadkol/Desktop/End-to-end-Medical-Chatbot-using-Llama2/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /opt/anaconda3/lib/python3.12/site-packages (5.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/tdvsqyyx5tj22_6kjnz3c4c40000gn/T/ipykernel_75025/1337643473.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_7Myivb_KdeTtvUZmMKfB2fpVaixRPYyhzjfVJnxprdGtxB7pSpKnnXXCja3bNYHUqRnegj\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the API key directly in the Python script\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_7Myivb_KdeTtvUZmMKfB2fpVaixRPYyhzjfVJnxprdGtxB7pSpKnnXXCja3bNYHUqRnegj\"\n",
    "\n",
    "# Now, print the API key to verify\n",
    "print(os.getenv(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/tdvsqyyx5tj22_6kjnz3c4c40000gn/T/ipykernel_75025/3397664757.py:27: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize Pinecone client with the correct API key and environment\n",
    "pinecone_client = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_API_ENV)\n",
    "\n",
    "# Initialize the index name and embeddings\n",
    "index_name = \"aihealthcarechatbot\"\n",
    "\n",
    "# Check if the index already exists\n",
    "if index_name not in pinecone_client.list_indexes():\n",
    "    pinecone_client.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  # Match the embedding size\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists. Skipping creation.\")\n",
    "\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Create the Pinecone vector store from the text chunks and embeddings\n",
    "docsearch = LangchainPinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/tdvsqyyx5tj22_6kjnz3c4c40000gn/T/ipykernel_75025/1065050653.py:4: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 768\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# Test the embedding dimensionality\n",
    "sample_embedding = embedding_model.embed_query(\"Test query\")\n",
    "print(f\"Embedding size: {len(sample_embedding)}\")  # Should print the dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing indexes: {'indexes': [{'deletion_protection': 'disabled',\n",
      "              'dimension': 2,\n",
      "              'host': 'medical-chatbot-19b1a0j.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'medical-chatbot',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}},\n",
      "             {'deletion_protection': 'disabled',\n",
      "              'dimension': 768,\n",
      "              'host': 'aihealthcarechatbot-19b1a0j.svc.aped-4627-b74a.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'aihealthcarechatbot',\n",
      "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n"
     ]
    }
   ],
   "source": [
    "# List all existing indexes\n",
    "print(\"Existing indexes:\", pinecone_client.list_indexes())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"/Users/nandinigadkol/Desktop/End-to-end-Medical-Chatbot-using-Llama2/model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctransformers in /opt/anaconda3/lib/python3.12/site-packages (0.2.27)\n",
      "Requirement already satisfied: huggingface-hub in /opt/anaconda3/lib/python3.12/site-packages (from ctransformers) (0.26.2)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ctransformers) (9.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub->ctransformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub->ctransformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub->ctransformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub->ctransformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7k/tdvsqyyx5tj22_6kjnz3c4c40000gn/T/ipykernel_75025/2586122779.py:12: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa(user_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: There are several acupressure points that can be used to relieve pressure on the shoulders. Here are a few options:\n",
      "\n",
      "1. The \"Third Eye\" point: Located between the eyebrows, this point is said to help alleviate tension and stress in the body.\n",
      "2. The \"Shoulder Well\" point: Located on the shoulder blade, this point is said to help relax the muscles in the shoulders and neck.\n",
      "3. The \"Liver 3\" point: Located on the upper back, this point is said to help reduce tension in the liver and gallbladder, which can contribute to pressure on the shoulders.\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "Sources:\n",
      "Unknown : Acupressure\n",
      "Therapist working acupressure points on a woman’s shoulder.(Photo Researchers, Inc. Reproduced by permission.)\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 36 ...\n",
      "Unknown : • a variable-pressure mattress whose sections can be\n",
      "individually inflated or deflated to redistribute pressure\n",
      "Pillows or foam wedges can prevent a bedridden\n",
      "patient’s ankles from irritating each oth ...\n",
      "\n",
      "Answer: Acupressure is a form of touch therapy that utilizes the principles of acupuncture and Chinese medicine. It involves stimulating specific points on the body with finger pressure instead of with needles, and is used to relieve a variety of symptoms and pain.\n",
      "\n",
      "Sources:\n",
      "Unknown : Definition\n",
      "Acupressure is a form of touch therapy that utilizes\n",
      "the principles of acupuncture and Chinese medicine. In\n",
      "acupressure, the same points on the body are used as in\n",
      "acupuncture, but are stim ...\n",
      "Unknown : instead of with the insertion of needles. Acupressure is\n",
      "used to relieve a variety of symptoms and pain.\n",
      "Purpose\n",
      "Acupressure massage performed by a therapist can be\n",
      "very effective both as prevention a ...\n",
      "Exiting... Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Accept user query\n",
    "    user_query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Exit condition\n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"Exiting... Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Process the query using the RetrievalQA pipeline\n",
    "    try:\n",
    "        response = qa(user_query)\n",
    "        # Print the answer\n",
    "        print(\"\\nAnswer:\", response['result'])\n",
    "        \n",
    "        # Optionally, print source documents\n",
    "        if 'source_documents' in response:\n",
    "            print(\"\\nSources:\")\n",
    "            for doc in response['source_documents']:\n",
    "                print(doc.metadata.get('source', 'Unknown'), \":\", doc.page_content[:200], \"...\")  # Truncated content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load pre-trained model for cosine similarity\n",
    "model_cosine = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(reference, response):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between reference and response texts.\n",
    "    :param reference: Reference text (string).\n",
    "    :param response: Model-generated response (string).\n",
    "    :return: Cosine similarity score as a float.\n",
    "    \"\"\"\n",
    "    ref_embedding = model_cosine.encode(reference, convert_to_tensor=True)\n",
    "    resp_embedding = model_cosine.encode(response, convert_to_tensor=True)\n",
    "    similarity_score = util.cos_sim(ref_embedding, resp_embedding).item()\n",
    "    return similarity_score\n",
    "\n",
    "# BLEU Score Calculation\n",
    "def calculate_bleu(reference, candidate, max_n=2):\n",
    "    \"\"\"\n",
    "    Calculates BLEU score from scratch.\n",
    "    :param reference: The reference text (string).\n",
    "    :param candidate: The candidate text generated by the model (string).\n",
    "    :param max_n: Maximum n-gram order to consider (default is bigram, 2).\n",
    "    :return: BLEU score as a float.\n",
    "    \"\"\"\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "\n",
    "    precisions = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        ref_ngrams = Counter(tuple(reference_tokens[i:i + n]) for i in range(len(reference_tokens) - n + 1))\n",
    "        cand_ngrams = Counter(tuple(candidate_tokens[i:i + n]) for i in range(len(candidate_tokens) - n + 1))\n",
    "        match_count = sum(min(count, cand_ngrams[ngram]) for ngram, count in ref_ngrams.items())\n",
    "        total_count = sum(cand_ngrams.values())\n",
    "        precision = match_count / total_count if total_count > 0 else 0\n",
    "        precisions.append(precision)\n",
    "\n",
    "    if all(p > 0 for p in precisions):\n",
    "        geometric_mean = math.exp(sum(math.log(p) for p in precisions) / max_n)\n",
    "    else:\n",
    "        geometric_mean = 0\n",
    "\n",
    "    ref_length = len(reference_tokens)\n",
    "    cand_length = len(candidate_tokens)\n",
    "    brevity_penalty = math.exp(1 - ref_length / cand_length) if cand_length > 0 and cand_length < ref_length else 1\n",
    "\n",
    "    bleu_score = brevity_penalty * geometric_mean\n",
    "    return bleu_score\n",
    "\n",
    "# ROUGE-N Calculation\n",
    "def calculate_rouge_n(reference, response, n=1):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE-N (precision, recall, F1-score).\n",
    "    :param reference: Reference text (string).\n",
    "    :param response: Model-generated text (string).\n",
    "    :param n: N-gram size (default is 1, unigram).\n",
    "    :return: Precision, Recall, and F1-score.\n",
    "    \"\"\"\n",
    "    reference_tokens = reference.split()\n",
    "    response_tokens = response.split()\n",
    "    ref_ngrams = Counter(tuple(reference_tokens[i:i + n]) for i in range(len(reference_tokens) - n + 1))\n",
    "    resp_ngrams = Counter(tuple(response_tokens[i:i + n]) for i in range(len(response_tokens) - n + 1))\n",
    "    overlap = sum(min(ref_ngrams[ngram], resp_ngrams[ngram]) for ngram in ref_ngrams)\n",
    "    ref_total = sum(ref_ngrams.values())\n",
    "    resp_total = sum(resp_ngrams.values())\n",
    "    precision = overlap / resp_total if resp_total > 0 else 0\n",
    "    recall = overlap / ref_total if ref_total > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "# ROUGE-L Calculation\n",
    "def calculate_rouge_l(reference, response):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE-L (Longest Common Subsequence).\n",
    "    :param reference: Reference text (string).\n",
    "    :param response: Model-generated text (string).\n",
    "    :return: Precision, Recall, and F1-score.\n",
    "    \"\"\"\n",
    "    reference_tokens = reference.split()\n",
    "    response_tokens = response.split()\n",
    "\n",
    "    def lcs_length(x, y):\n",
    "        dp = [[0] * (len(y) + 1) for _ in range(len(x) + 1)]\n",
    "        for i in range(1, len(x) + 1):\n",
    "            for j in range(1, len(y) + 1):\n",
    "                if x[i - 1] == y[j - 1]:\n",
    "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "        return dp[-1][-1]\n",
    "\n",
    "    lcs_len = lcs_length(reference_tokens, response_tokens)\n",
    "    precision = lcs_len / len(response_tokens) if len(response_tokens) > 0 else 0\n",
    "    recall = lcs_len / len(reference_tokens) if len(reference_tokens) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Closest Reference Finder\n",
    "def get_closest_reference(user_query, reference_answers):\n",
    "    \"\"\"\n",
    "    Find the closest reference answer for the given user query.\n",
    "    :param user_query: The query input by the user.\n",
    "    :param reference_answers: A dictionary of reference answers.\n",
    "    :return: Closest matching reference answer as a string.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    question_embedding = model.encode([user_query])\n",
    "    reference_embeddings = model.encode(list(reference_answers.keys()))\n",
    "    similarities = np.dot(question_embedding, reference_embeddings.T)\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    return list(reference_answers.values())[most_similar_idx] if similarities[0][most_similar_idx] > 0 else None\n",
    "\n",
    "# Evaluation Workflow\n",
    "def evaluate_llama_response(user_query, reference_answers):\n",
    "    \"\"\"\n",
    "    Generate a response from LLaMA and evaluate it against reference answers.\n",
    "    :param user_query: Query input by the user (string).\n",
    "    :param reference_answers: Dictionary of reference answers.\n",
    "    :return: Dictionary of metrics and the generated response.\n",
    "    \"\"\"\n",
    "    result = qa.run(user_query)  # Assuming `qa` is your RetrievalQA chain\n",
    "    generated_response = result['result']\n",
    "\n",
    "    closest_reference = get_closest_reference(user_query, reference_answers)\n",
    "    if closest_reference is None:\n",
    "        print(\"No relevant reference found for the query.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"User Query: {user_query}\")\n",
    "    print(f\"Generated Response: {generated_response}\")\n",
    "    print(f\"Reference Answer: {closest_reference}\")\n",
    "\n",
    "    cosine_score = calculate_cosine_similarity(closest_reference, generated_response)\n",
    "    bleu_score = calculate_bleu(closest_reference, generated_response)\n",
    "    rouge_precision, rouge_recall, rouge_f1 = calculate_rouge_n(closest_reference, generated_response, n=1)\n",
    "    rouge_l_precision, rouge_l_recall, rouge_l_f1 = calculate_rouge_l(closest_reference, generated_response)\n",
    "\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"Cosine Similarity: {cosine_score:.4f}\")\n",
    "    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "    print(f\"ROUGE-1 -> Precision: {rouge_precision:.4f}, Recall: {rouge_recall:.4f}, F1: {rouge_f1:.4f}\")\n",
    "    print(f\"ROUGE-L -> Precision: {rouge_l_precision:.4f}, Recall: {rouge_l_recall:.4f}, F1: {rouge_l_f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"generated_response\": generated_response,\n",
    "        \"reference_answer\": closest_reference,\n",
    "        \"cosine_similarity\": cosine_score,\n",
    "        \"bleu_score\": bleu_score,\n",
    "        \"rouge_1\": {\"precision\": rouge_precision, \"recall\": rouge_recall, \"f1\": rouge_f1},\n",
    "        \"rouge_l\": {\"precision\": rouge_l_precision, \"recall\": rouge_l_recall, \"f1\": rouge_l_f1}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating query: What is acupressure?\n",
      "\n",
      "Evaluating query: What is angiography?\n",
      "\n",
      "Evaluating query: What is anosmia?\n",
      "\n",
      "Evaluating query: How is anosmia treated?\n",
      "\n",
      "Evaluating query: What causes alopecia?\n",
      "\n",
      "Evaluating query: What is male pattern baldness?\n",
      "\n",
      "Evaluating query: What are the symptoms of anosmia?\n",
      "\n",
      "Evaluating query: What is the purpose of angiography?\n",
      "\n",
      "Evaluating query: How is alopecia diagnosed?\n",
      "\n",
      "Evaluating query: Can alopecia be cured?\n",
      "\n",
      "========================================\n",
      "Query: What is acupressure?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.9644\n",
      "  BLEU Score: 0.1969\n",
      "  ROUGE-1 F1: 0.5517\n",
      "  ROUGE-1 Recall: 0.3810\n",
      "  ROUGE-L F1: 0.5517\n",
      "  ROUGE-L Recall: 0.3810\n",
      "\n",
      "========================================\n",
      "Query: What is angiography?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.9537\n",
      "  BLEU Score: 0.2795\n",
      "  ROUGE-1 F1: 0.4158\n",
      "  ROUGE-1 Recall: 0.5676\n",
      "  ROUGE-L F1: 0.3960\n",
      "  ROUGE-L Recall: 0.5405\n",
      "\n",
      "========================================\n",
      "Query: What is anosmia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8383\n",
      "  BLEU Score: 0.1633\n",
      "  ROUGE-1 F1: 0.2821\n",
      "  ROUGE-1 Recall: 0.2292\n",
      "  ROUGE-L F1: 0.2308\n",
      "  ROUGE-L Recall: 0.1875\n",
      "\n",
      "========================================\n",
      "Query: How is anosmia treated?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.3753\n",
      "  BLEU Score: 0.0492\n",
      "  ROUGE-1 F1: 0.1795\n",
      "  ROUGE-1 Recall: 0.1458\n",
      "  ROUGE-L F1: 0.1026\n",
      "  ROUGE-L Recall: 0.0833\n",
      "\n",
      "========================================\n",
      "Query: What causes alopecia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8107\n",
      "  BLEU Score: 0.0233\n",
      "  ROUGE-1 F1: 0.3137\n",
      "  ROUGE-1 Recall: 0.1951\n",
      "  ROUGE-L F1: 0.3137\n",
      "  ROUGE-L Recall: 0.1951\n",
      "\n",
      "========================================\n",
      "Query: What is male pattern baldness?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.9494\n",
      "  BLEU Score: 0.4598\n",
      "  ROUGE-1 F1: 0.6410\n",
      "  ROUGE-1 Recall: 0.7353\n",
      "  ROUGE-L F1: 0.5897\n",
      "  ROUGE-L Recall: 0.6765\n",
      "\n",
      "========================================\n",
      "Query: What are the symptoms of anosmia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8945\n",
      "  BLEU Score: 0.1136\n",
      "  ROUGE-1 F1: 0.3396\n",
      "  ROUGE-1 Recall: 0.2727\n",
      "  ROUGE-L F1: 0.1509\n",
      "  ROUGE-L Recall: 0.1212\n",
      "\n",
      "========================================\n",
      "Query: What is the purpose of angiography?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.7210\n",
      "  BLEU Score: 0.1146\n",
      "  ROUGE-1 F1: 0.2647\n",
      "  ROUGE-1 Recall: 0.2432\n",
      "  ROUGE-L F1: 0.1765\n",
      "  ROUGE-L Recall: 0.1622\n",
      "\n",
      "========================================\n",
      "Query: How is alopecia diagnosed?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8861\n",
      "  BLEU Score: 0.0708\n",
      "  ROUGE-1 F1: 0.2258\n",
      "  ROUGE-1 Recall: 0.4375\n",
      "  ROUGE-L F1: 0.1935\n",
      "  ROUGE-L Recall: 0.3750\n",
      "\n",
      "========================================\n",
      "Query: Can alopecia be cured?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8041\n",
      "  BLEU Score: 0.1131\n",
      "  ROUGE-1 F1: 0.2400\n",
      "  ROUGE-1 Recall: 0.2368\n",
      "  ROUGE-L F1: 0.1333\n",
      "  ROUGE-L Recall: 0.1316\n",
      "\n",
      "========================================\n",
      "Average Metrics Across All Queries:\n",
      "  Average Cosine Similarity: 0.8198\n",
      "  Average BLEU Score: 0.1584\n",
      "  Average ROUGE-1 F1: 0.3454\n",
      "  Average ROUGE-1 Recall: 0.3444\n",
      "  Average ROUGE-L F1: 0.2839\n",
      "  Average ROUGE-L Recall: 0.2854\n"
     ]
    }
   ],
   "source": [
    "from references import reference_answers  # Replace 'reference_answers' with your file name\n",
    "\n",
    "# Function to evaluate LLaMA responses\n",
    "def evaluate_llama_response(user_query):\n",
    "    \"\"\"\n",
    "    Generate a response from LLaMA and evaluate it against reference answers.\n",
    "    :param user_query: Query input by the user (string).\n",
    "    :return: Dictionary of metrics and the generated response.\n",
    "    \"\"\"\n",
    "    # Generate a response from the LLaMA model\n",
    "    result = qa({\"query\": user_query})  # Use the `__call__` method to handle multiple output keys\n",
    "    generated_response = result[\"result\"]  # Access the \"result\" key for the generated response\n",
    "\n",
    "    # Find the closest reference answer\n",
    "    closest_reference = get_closest_reference(user_query, reference_answers)\n",
    "    if closest_reference is None:\n",
    "        print(\"No relevant reference found for the query.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    cosine_score = calculate_cosine_similarity(closest_reference, generated_response)\n",
    "    bleu_score = calculate_bleu(closest_reference, generated_response)\n",
    "    rouge_precision, rouge_recall, rouge_f1 = calculate_rouge_n(closest_reference, generated_response, n=1)\n",
    "    rouge_l_precision, rouge_l_recall, rouge_l_f1 = calculate_rouge_l(closest_reference, generated_response)\n",
    "\n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"cosine_similarity\": cosine_score,\n",
    "        \"bleu_score\": bleu_score,\n",
    "        \"rouge_1\": {\"precision\": rouge_precision, \"recall\": rouge_recall, \"f1\": rouge_f1},\n",
    "        \"rouge_l\": {\"precision\": rouge_l_precision, \"recall\": rouge_l_recall, \"f1\": rouge_l_f1}\n",
    "    }\n",
    "\n",
    "# Function to evaluate multiple queries and calculate averages\n",
    "def evaluate_multiple_queries_with_averages(user_queries):\n",
    "    \"\"\"\n",
    "    Evaluate multiple queries using the LLaMA model and calculate average metrics.\n",
    "    :param user_queries: List of user queries to evaluate.\n",
    "    :return: List of evaluation results and average metrics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_metrics = {\n",
    "        \"cosine_similarity\": 0,\n",
    "        \"bleu_score\": 0,\n",
    "        \"rouge_1_f1\": 0,\n",
    "        \"rouge_l_f1\": 0,\n",
    "        \"rouge_1_recall\": 0,\n",
    "        \"rouge_l_recall\": 0\n",
    "    }\n",
    "    num_queries = len(user_queries)\n",
    "\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nEvaluating query: {query}\")\n",
    "        result = evaluate_llama_response(query)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            # Accumulate metrics for averaging\n",
    "            total_metrics[\"cosine_similarity\"] += result[\"cosine_similarity\"]\n",
    "            total_metrics[\"bleu_score\"] += result[\"bleu_score\"]\n",
    "            total_metrics[\"rouge_1_f1\"] += result[\"rouge_1\"][\"f1\"]\n",
    "            total_metrics[\"rouge_l_f1\"] += result[\"rouge_l\"][\"f1\"]\n",
    "            total_metrics[\"rouge_1_recall\"] += result[\"rouge_1\"][\"recall\"]\n",
    "            total_metrics[\"rouge_l_recall\"] += result[\"rouge_l\"][\"recall\"]\n",
    "\n",
    "    # Calculate average metrics\n",
    "    average_metrics = {key: value / num_queries for key, value in total_metrics.items()}\n",
    "\n",
    "    return results, average_metrics\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_queries = [\n",
    "        \"What is acupressure?\",\n",
    "        \"What is angiography?\",\n",
    "        \"What is anosmia?\",\n",
    "        \"How is anosmia treated?\",\n",
    "        \"What causes alopecia?\",\n",
    "        \"What is male pattern baldness?\",\n",
    "        \"What are the symptoms of anosmia?\",\n",
    "        \"What is the purpose of angiography?\",\n",
    "        \"How is alopecia diagnosed?\",\n",
    "        \"Can alopecia be cured?\"\n",
    "    ]\n",
    "\n",
    "    evaluation_results, average_metrics = evaluate_multiple_queries_with_averages(user_queries)\n",
    "\n",
    "    # Print a summary of the evaluation results\n",
    "    for result in evaluation_results:\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(f\"Query: {result['query']}\")\n",
    "        print(\"Metrics:\")\n",
    "        print(f\"  Cosine Similarity: {result['cosine_similarity']:.4f}\")\n",
    "        print(f\"  BLEU Score: {result['bleu_score']:.4f}\")\n",
    "        print(f\"  ROUGE-1 F1: {result['rouge_1']['f1']:.4f}\")\n",
    "        print(f\"  ROUGE-1 Recall: {result['rouge_1']['recall']:.4f}\")\n",
    "        print(f\"  ROUGE-L F1: {result['rouge_l']['f1']:.4f}\")\n",
    "        print(f\"  ROUGE-L Recall: {result['rouge_l']['recall']:.4f}\")\n",
    "\n",
    "    # Print average metrics\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"Average Metrics Across All Queries:\")\n",
    "    print(f\"  Average Cosine Similarity: {average_metrics['cosine_similarity']:.4f}\")\n",
    "    print(f\"  Average BLEU Score: {average_metrics['bleu_score']:.4f}\")\n",
    "    print(f\"  Average ROUGE-1 F1: {average_metrics['rouge_1_f1']:.4f}\")\n",
    "    print(f\"  Average ROUGE-1 Recall: {average_metrics['rouge_1_recall']:.4f}\")\n",
    "    print(f\"  Average ROUGE-L F1: {average_metrics['rouge_l_f1']:.4f}\")\n",
    "    print(f\"  Average ROUGE-L Recall: {average_metrics['rouge_l_recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating query: What is acupressure?\n",
      "\n",
      "Evaluating query: What is angiography?\n",
      "\n",
      "Evaluating query: What is anosmia?\n",
      "\n",
      "Evaluating query: How is anosmia treated?\n",
      "\n",
      "Evaluating query: What causes alopecia?\n",
      "\n",
      "Evaluating query: What is male pattern baldness?\n",
      "\n",
      "Evaluating query: What are the symptoms of anosmia?\n",
      "\n",
      "Evaluating query: What is the purpose of angiography?\n",
      "\n",
      "Evaluating query: How is alopecia diagnosed?\n",
      "\n",
      "Evaluating query: Can alopecia be cured?\n",
      "\n",
      "========================================\n",
      "Query: What is acupressure?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.9644\n",
      "  BLEU Score: 0.1969\n",
      "  ROUGE-1 F1: 0.5517\n",
      "  ROUGE-L F1: 0.5517\n",
      "\n",
      "========================================\n",
      "Query: What is angiography?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.9236\n",
      "  BLEU Score: 0.0446\n",
      "  ROUGE-1 F1: 0.3913\n",
      "  ROUGE-L F1: 0.3913\n",
      "\n",
      "========================================\n",
      "Query: What is anosmia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8603\n",
      "  BLEU Score: 0.0158\n",
      "  ROUGE-1 F1: 0.3103\n",
      "  ROUGE-L F1: 0.2759\n",
      "\n",
      "========================================\n",
      "Query: How is anosmia treated?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.3321\n",
      "  BLEU Score: 0.0951\n",
      "  ROUGE-1 F1: 0.2400\n",
      "  ROUGE-L F1: 0.1600\n",
      "\n",
      "========================================\n",
      "Query: What causes alopecia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8348\n",
      "  BLEU Score: 0.0000\n",
      "  ROUGE-1 F1: 0.1587\n",
      "  ROUGE-L F1: 0.1270\n",
      "\n",
      "========================================\n",
      "Query: What is male pattern baldness?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8359\n",
      "  BLEU Score: 0.4170\n",
      "  ROUGE-1 F1: 0.6000\n",
      "  ROUGE-L F1: 0.5500\n",
      "\n",
      "========================================\n",
      "Query: What are the symptoms of anosmia?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8808\n",
      "  BLEU Score: 0.0659\n",
      "  ROUGE-1 F1: 0.2278\n",
      "  ROUGE-L F1: 0.1266\n",
      "\n",
      "========================================\n",
      "Query: What is the purpose of angiography?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.7376\n",
      "  BLEU Score: 0.0840\n",
      "  ROUGE-1 F1: 0.2045\n",
      "  ROUGE-L F1: 0.1364\n",
      "\n",
      "========================================\n",
      "Query: How is alopecia diagnosed?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.8877\n",
      "  BLEU Score: 0.0443\n",
      "  ROUGE-1 F1: 0.2500\n",
      "  ROUGE-L F1: 0.1833\n",
      "\n",
      "========================================\n",
      "Query: Can alopecia be cured?\n",
      "Metrics:\n",
      "  Cosine Similarity: 0.7352\n",
      "  BLEU Score: 0.0772\n",
      "  ROUGE-1 F1: 0.2687\n",
      "  ROUGE-L F1: 0.1493\n",
      "\n",
      "========================================\n",
      "Average Metrics Across All Queries:\n",
      "  Average Cosine Similarity: 0.7992\n",
      "  Average BLEU Score: 0.1041\n",
      "  Average ROUGE-1 F1: 0.3203\n",
      "  Average ROUGE-L F1: 0.2651\n"
     ]
    }
   ],
   "source": [
    "from references import reference_answers  # Replace 'reference_answers' with your file name\n",
    "\n",
    "# Function to evaluate LLaMA responses\n",
    "def evaluate_llama_response(user_query):\n",
    "    \"\"\"\n",
    "    Generate a response from LLaMA and evaluate it against reference answers.\n",
    "    :param user_query: Query input by the user (string).\n",
    "    :return: Dictionary of metrics and the generated response.\n",
    "    \"\"\"\n",
    "    # Generate a response from the LLaMA model\n",
    "    result = qa({\"query\": user_query})  # Use the `__call__` method to handle multiple output keys\n",
    "    generated_response = result[\"result\"]  # Access the \"result\" key for the generated response\n",
    "\n",
    "    # Find the closest reference answer\n",
    "    closest_reference = get_closest_reference(user_query, reference_answers)\n",
    "    if closest_reference is None:\n",
    "        print(\"No relevant reference found for the query.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    cosine_score = calculate_cosine_similarity(closest_reference, generated_response)\n",
    "    bleu_score = calculate_bleu(closest_reference, generated_response)\n",
    "    rouge_precision, rouge_recall, rouge_f1 = calculate_rouge_n(closest_reference, generated_response, n=1)\n",
    "    rouge_l_precision, rouge_l_recall, rouge_l_f1 = calculate_rouge_l(closest_reference, generated_response)\n",
    "\n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"cosine_similarity\": cosine_score,\n",
    "        \"bleu_score\": bleu_score,\n",
    "        \"rouge_1\": {\"precision\": rouge_precision, \"recall\": rouge_recall, \"f1\": rouge_f1},\n",
    "        \"rouge_l\": {\"precision\": rouge_l_precision, \"recall\": rouge_l_recall, \"f1\": rouge_l_f1}\n",
    "    }\n",
    "\n",
    "# Function to evaluate multiple queries and calculate averages\n",
    "def evaluate_multiple_queries_with_averages(user_queries):\n",
    "    \"\"\"\n",
    "    Evaluate multiple queries using the LLaMA model and calculate average metrics.\n",
    "    :param user_queries: List of user queries to evaluate.\n",
    "    :return: List of evaluation results and average metrics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_metrics = {\n",
    "        \"cosine_similarity\": 0,\n",
    "        \"bleu_score\": 0,\n",
    "        \"rouge_1_f1\": 0,\n",
    "        \"rouge_l_f1\": 0\n",
    "    }\n",
    "    num_queries = len(user_queries)\n",
    "\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nEvaluating query: {query}\")\n",
    "        result = evaluate_llama_response(query)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            # Accumulate metrics for averaging\n",
    "            total_metrics[\"cosine_similarity\"] += result[\"cosine_similarity\"]\n",
    "            total_metrics[\"bleu_score\"] += result[\"bleu_score\"]\n",
    "            total_metrics[\"rouge_1_f1\"] += result[\"rouge_1\"][\"f1\"]\n",
    "            total_metrics[\"rouge_l_f1\"] += result[\"rouge_l\"][\"f1\"]\n",
    "\n",
    "    # Calculate average metrics\n",
    "    average_metrics = {key: value / num_queries for key, value in total_metrics.items()}\n",
    "\n",
    "    return results, average_metrics\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_queries = [\n",
    "        \"What is acupressure?\",\n",
    "        \"What is angiography?\",\n",
    "        \"What is anosmia?\",\n",
    "        \"How is anosmia treated?\",\n",
    "        \"What causes alopecia?\",\n",
    "        \"What is male pattern baldness?\",\n",
    "        \"What are the symptoms of anosmia?\",\n",
    "        \"What is the purpose of angiography?\",\n",
    "        \"How is alopecia diagnosed?\",\n",
    "        \"Can alopecia be cured?\"\n",
    "    ]\n",
    "\n",
    "    evaluation_results, average_metrics = evaluate_multiple_queries_with_averages(user_queries)\n",
    "\n",
    "    # Print a summary of the evaluation results\n",
    "    for result in evaluation_results:\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(f\"Query: {result['query']}\")\n",
    "        print(\"Metrics:\")\n",
    "        print(f\"  Cosine Similarity: {result['cosine_similarity']:.4f}\")\n",
    "        print(f\"  BLEU Score: {result['bleu_score']:.4f}\")\n",
    "        print(f\"  ROUGE-1 F1: {result['rouge_1']['f1']:.4f}\")\n",
    "        print(f\"  ROUGE-L F1: {result['rouge_l']['f1']:.4f}\")\n",
    "\n",
    "    # Print average metrics\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"Average Metrics Across All Queries:\")\n",
    "    print(f\"  Average Cosine Similarity: {average_metrics['cosine_similarity']:.4f}\")\n",
    "    print(f\"  Average BLEU Score: {average_metrics['bleu_score']:.4f}\")\n",
    "    print(f\"  Average ROUGE-1 F1: {average_metrics['rouge_1_f1']:.4f}\")\n",
    "    print(f\"  Average ROUGE-L F1: {average_metrics['rouge_l_f1']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
